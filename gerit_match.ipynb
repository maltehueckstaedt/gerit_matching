{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maltehueckstaedt/gerit_matching/blob/main/gerit_match.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15hMpVh2h_-D"
      },
      "source": [
        "# GERIT PRE-Matching mit OpenAI-Embeddings\n",
        "\n",
        "Im folgenden wird ein Notebook entworfen, dass das derzeitige Matching der HEX der Daten mit GERIT-Organisationen erleichtern soll. Im Derzeitigen Stand geht folgendermaßen vor:\n",
        "\n",
        "Es wird von einem klassischen Cleaning der Organisations-Variable, wie sie aus den Scrapiung kommt, abgesehen, weil es im vergleich zum folgenden Vorgehen (und angesichts des Umstandes, dass wir ja die *wahren* Organisationennamen schon kennen) uneffizient und die Gefahr von Artfacten höher erscheint.\n",
        "\n",
        "Statt eines klassischen Cleanings mit Hilfe von LLMs wird eine Funktion implementiert,die nach Entsprechungen in der Liste der GERIT-Organisationen. Dafür werden mit OpenAI Embeddings Vektor-Repräsentationen aller GERIT-Namen erstellt. Ein *„Retriever“* durchsucht diese Vektoren, um die besten Übereinstimmungen zu einem gegebenen Namen (also den Organisationsnamen aus dem Scraping) zu finden. Das Modell kann z. B. erkennen, dass „*Institut für Biologie*“ und „*Department Biologie*“ wahrscheinlich dasselbe meinen.\n",
        "\n",
        "Für jede Organisation wird überprüft, ob es eine exakte Übereinstimmung gibt. Falls ja, wird der offizielle GERIT-Name übernommen. Falls keine exakte Übereinstimmung gefunden wird, kommt ein Fuzzy Matching zum Einsatz, bei dem ein kosinusbasierter Score berechnet wird (0 = völlig unterschiedliche Begriffe, 1 = perfekte Übereinstimmung). Ist der Score hoch genug (aktuell: > 0.5), wird der bestpassende GERIT-Treffer übernommen. Falls keine passende Entsprechung gefunden wird, bleibt der Wert NA.\n",
        "\n",
        "Vorteile: Die Funktion spart Zeit – es werden derzeit 20.000 Zeilen und 250 unique Werte in etwa 1,5 Minuten umcodiert. Zudem ist kein manuelles Coding oder eine zusätzliche Aufbereitung der Organisationsvariablen nötig. Mit dem Score-Cutoff kann weiterhin die Konservativität des tools gesteuert werden.\n",
        "\n",
        "Nachteile: Die Qualität der Zuordnung muss geprüft werden, und es bleibt die Frage, wie sich das neue >>Cleaning>> oder Vor-Matching auf nachfolgende Analysen auswirkt.\n",
        "\n",
        "## Programmierung der Funktion\n",
        "\n",
        "### Einrichtung Arbeitspfad\n",
        "\n",
        "In einem ersten Schritt überprüfen wir unseren derzeitgen Arbeitspfad (in dem Fall das wir lokal arbeiten)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0tiI6aph_-E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"c:/Users/Hueck/OneDrive/Dokumente/GitHub/gerit_matching\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbWhxtqh_-F"
      },
      "source": [
        "### Laden und checke der Daten\n",
        "\n",
        "Wir laden einerseits testweise der Daten (inkl. der Organisationsvariable) der HHU, andererseits die GERIT-Daten der hhu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w42l_EGh_-F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "db_hhu = pd.read_csv(\"data\\hhu_db_raw.csv\")\n",
        "#db_hhu = db_hhu.sample(n=200, random_state=42)\n",
        "hhu_gerit = pd.read_excel(\"data/hhu_gerit.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlVHC7Xvh_-F"
      },
      "source": [
        "Wir zeigen in folgenden die Spaltennamen, den Typ der Variable `organisation_mehrere` und ihre uniquen Werte an."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCLTFA5ah_-G"
      },
      "outputs": [],
      "source": [
        "db_hhu.columns\n",
        "print(db_hhu[\"organisation_mehrere\"].dtype)\n",
        "print(db_hhu[\"organisation_mehrere\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unabhängig davon, welcher Typ die Variable `organisation_mehrere` tatsächlich ist, definieren wandeln wie die Varibale in einen String.\n",
        "\n",
        "Anschließend erzeugen wir mit `set()` eine leere Menge `unique_values`. `set()` erzeugt eine ungeordnete Sammlung von einzigartigen Elementen. Sets entfernen automatisch doppelte Werte und bieten effiziente Methoden zum Hinzufügen, Entfernen und Überprüfen von Elementen.\n",
        "\n",
        "\n",
        "Wir nehmen dann den Datensatz `db_hhu` und entfernen alle `NaN`. Anschließend wird für jeden verbleibenden Wert die Funktion `apply()` aufgerufen. Innerhalb der Funktion wird der Text jedes Wertes an den Semikolons geteilt, sodass eine Liste von Werten entsteht. Diese Werte werden dann bereinigt, indem führende und nachstehende Leerzeichen entfernt werden und leere oder mit \"NA\" (unabhängig von der Groß-/Kleinschreibung) markierte Werte ausgeschlossen werden. Alle bereinigten, nicht leeren und nicht \"NA\"-Werte werden anschließend dem `unique_values`-Set hinzugefügt, wobei nur einzigartige Werte beibehalten werden.\n",
        "\n",
        "Abschließend wird zur Information die Anzahl uniquer Organisationen sowie die Merkmale ausgegeben."
      ],
      "metadata": {
        "id": "kL3k1mBenw4P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "civwAsyPh_-G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "db_hhu[\"organisation_mehrere\"] = db_hhu[\"organisation_mehrere\"].astype(str)\n",
        "\n",
        "unique_values = set()\n",
        "db_hhu[\"organisation_mehrere\"].dropna().apply(lambda x: unique_values.update(\n",
        "    [val.strip() for val in x.split(\";\") if val.strip() and val.strip().upper() != \"NA\"]\n",
        "))\n",
        "\n",
        "# Ergebnis ausgeben\n",
        "print(f\"Anzahl einzigartiger Werte: {len(unique_values)}\")\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiYy15bFh_-G"
      },
      "source": [
        "### Lade openAI API\n",
        "\n",
        "Für das Matching der Organisationsnamen, die aus dem Scraping kommen mit denen der GERIT-Organisationen benötigen wir Embeddings. Dies Embeddings werden mit Hilfe der openAI-API erzeugt. Aus diesem Grund wird der openAI-API-Key im folgenden aus dem Enviorment geladen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lybg0pMh_-G"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im folgenden wird die OpenAI-API verwendet, um Embeddings der GERIT-Organisationen zu erzeugen und mit hilfe von Langchain eine In-Memory-Vektordatenbank für GERIT-Organisationen zu erstellen.\n",
        "\n",
        "In einem ersten Schritt wird das OpenAI-Embedding-Modell `text-embedding-3-large` initialisiert. Danach wird eine InMemoryVectorStore-Datenbank erstellt, die diese Vektoren speichert.\n",
        "\n",
        "Nun werden die GERIT-Organisationen aus dem Pandas-DataFrame (`hhu_gerit[\"Einrichtung\"]`) in `Document`-Objekte umgewandelt. Diese Dokumente enthalten die Namen der Einrichtungen als `page_content`. Schließlich werden diese Dokumente mit ihren Embeddings in die Vektordatenbank eingefügt. Dadurch können später Ähnlichkeitsabfragen durchgeführt werden, um Organisationen mit ähnlichen Namen oder thematischen Schwerpunkten zu finden."
      ],
      "metadata": {
        "id": "LW9dxoWYsj8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z95eeAPqh_-G"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import chain\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "\n",
        "docs = [Document(page_content=einrichtung) for einrichtung in hhu_gerit[\"Einrichtung\"].tolist()]\n",
        "vector_store.add_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_IDBFi8utNpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definiere den Retriever als Chain mit Scores\n",
        "@chain\n",
        "def retriever(query: str) -> List[Document]:\n",
        "    results = vector_store.similarity_search_with_score(query, k=5)\n",
        "    docs, scores = zip(*results) if results else ([], [])\n",
        "\n",
        "    for doc, score in zip(docs, scores):\n",
        "        doc.metadata[\"score\"] = score  # Füge den Score als Metadaten hinzu\n",
        "\n",
        "    return list(docs)\n",
        "\n",
        "# Beschreibung für den Retriever\n",
        "description = (\n",
        "    \"Sucht nach gültigen Eigennamen basierend auf einer ungefähren Eingabe und gibt die Ähnlichkeitsscores zurück. \"\n",
        "    \"Falls keine passende Entsprechung gefunden wird, wird 'NA' zurückgegeben.\"\n",
        ")\n",
        "\n",
        "# Retriever-Tool erstellen\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"search_proper_nouns_with_score\",\n",
        "    description=description,\n",
        ")\n"
      ],
      "metadata": {
        "id": "HtEsZuk6tKOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tM62Qxhh_-H"
      },
      "outputs": [],
      "source": [
        "query = \"Chemie\"\n",
        "results = retriever.invoke(query)\n",
        "\n",
        "# Ergebnisse anzeigen\n",
        "for doc in results:\n",
        "    print(f\"Text: {doc.page_content}, Score: {doc.metadata['score']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvUN8-L4h_-H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def match_unique_organisations(org_series, mapping_dict, retriever):\n",
        "    \"\"\"\n",
        "    Funktion, die nur einzigartige Werte der Organisationen verarbeitet und eine detaillierte Matching-Tabelle erstellt.\n",
        "\n",
        "    :param org_series: Pandas Series mit den ursprünglichen Organisationen\n",
        "    :param mapping_dict: Dictionary mit bekannten exakten Zuordnungen\n",
        "    :param retriever: Retriever zur unscharfen Suche\n",
        "    :return:\n",
        "        - recode_dict: Dictionary mit den rekodierten Werten (Originalwert → gematchter Wert)\n",
        "        - matching_df: DataFrame mit Matching-Details (ursprünglicher Wert, gematchter Wert, Matching-Art, Score)\n",
        "    \"\"\"\n",
        "    print(f\"Anzahl einzigartiger Organisationen in den Eingabedaten: {len(org_series)}\")\n",
        "\n",
        "    recode_dict = {}\n",
        "    matching_data = []  # Liste für die Matching-Ergebnisse\n",
        "\n",
        "    for org in org_series:\n",
        "        orgs = [o.strip() for o in org.split(';')]  # Aufteilen bei \";\", Leerzeichen entfernen\n",
        "        matched_orgs = []\n",
        "        match_details = []  # Speichert Match-Typ und Score für jede Organisation in einer Zeile\n",
        "\n",
        "        for o in orgs:\n",
        "            match_type = \"Keine Übereinstimmung\"\n",
        "            score = None\n",
        "            matched_value = None\n",
        "\n",
        "            # 1. Prüfen, ob eine exakte Übereinstimmung existiert\n",
        "            if o in mapping_dict:\n",
        "                matched_value = mapping_dict[o]\n",
        "                match_type = \"Exakt\"\n",
        "                score = 1.0  # Exakte Matches haben Score 1.0\n",
        "                print(f\"Exakte Übereinstimmung gefunden: '{o}' → '{matched_value}'\")\n",
        "            else:\n",
        "                # 2. Falls keine exakte Übereinstimmung, unscharfe Suche über den Retriever\n",
        "                results = retriever.invoke(o)  # invoke nutzen, da retriever eine Chain ist\n",
        "\n",
        "                if results and results[0].metadata.get(\"score\", 0) >= 0.5:\n",
        "                    matched_value = results[0].page_content\n",
        "                    score = results[0].metadata[\"score\"]\n",
        "                    match_type = \"Fuzzy\"\n",
        "                    print(f\"Fuzzy Match gefunden: '{o}' → '{matched_value}' (Score: {score:.2f})\")\n",
        "                else:\n",
        "                    print(f\"Kein passender Match für '{o}' gefunden.\")\n",
        "\n",
        "            # Speichern des Matches\n",
        "            matched_orgs.append(matched_value if matched_value else o)  # Falls kein Match, Original behalten\n",
        "            match_details.append({\n",
        "                \"Ursprünglicher Wert\": o,\n",
        "                \"Gematchter GERIT-Wert\": matched_value,\n",
        "                \"Matching-Art\": match_type,\n",
        "                \"Score\": score\n",
        "            })\n",
        "\n",
        "        # Rekodierungs-Dictionary speichern\n",
        "        recode_dict[org] = \"; \".join([m for m in matched_orgs if m]) if matched_orgs else None\n",
        "\n",
        "        # Matching-Details zur Liste hinzufügen\n",
        "        matching_data.extend(match_details)\n",
        "\n",
        "    # DataFrame aus den Matching-Daten erstellen\n",
        "    matching_df = pd.DataFrame(matching_data)\n",
        "\n",
        "    return recode_dict, matching_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhaoKuarh_-H"
      },
      "outputs": [],
      "source": [
        "recode_dict, matching_df = match_unique_organisations(unique_values, mapping_dict, retriever)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMeLNoYVh_-H"
      },
      "outputs": [],
      "source": [
        "def apply_matched_organisations(org_series, recode_dict):\n",
        "    \"\"\"\n",
        "    Wendet das zuvor berechnete Matching Dictionary auf die originale Spalte an,\n",
        "    indem alle Organisationen innerhalb eines Eintrags korrekt ersetzt werden.\n",
        "\n",
        "    :param org_series: Pandas Series mit den ursprünglichen Organisationen\n",
        "    :param recode_dict: Dictionary mit den rekodierten Werten (Originalwert → gematchter Wert)\n",
        "    :return: Pandas Series mit den rekodierten Organisationen\n",
        "    \"\"\"\n",
        "    def map_multiple_orgs(org):\n",
        "        if pd.isna(org):\n",
        "            return None  # Fehlende Werte beibehalten\n",
        "\n",
        "        org_list = [o.strip() for o in org.split(';')]  # Mehrere Organisationen aufteilen\n",
        "        matched_list = [recode_dict.get(o, o) for o in org_list]  # Falls kein Match gefunden wird, Originalwert behalten\n",
        "        matched_list = [m for m in matched_list if m]  # Leere Werte entfernen\n",
        "\n",
        "        return \"; \".join(matched_list) if matched_list else None  # Falls keine Matches, None zurückgeben\n",
        "\n",
        "    return org_series.apply(map_multiple_orgs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gRsVL-Gh_-H"
      },
      "outputs": [],
      "source": [
        "db_hhu[\"gerit_match\"] = apply_matched_organisations(db_hhu[\"organisation_mehrere\"], recode_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_J68PXAh_-I"
      },
      "outputs": [],
      "source": [
        "matching_df.to_excel(\"matching_results.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "match_gerit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}